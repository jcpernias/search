---
title: "Bias and Size Effects of Price-Comparison Platforms: Theory and Experimental Evidence"
output:
  pdf_document: 
    number_sections: true
  html_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = " ")

library(gridExtra)
library(tidyverse)
library(broom)
library(knitr)
library(lazyeval)
```


# Introduction

This file documents the data and the statistical analyses of the paper _`Bias and Size Effects of Price-Comparison Platforms: Theory and Experimental Evidence'_ by ... The R code that compute the statistics and do the plots is also reported. 

## Package loading

The following R packages were needed:
```{r packages, eval=FALSE}
library(gridExtra)
library(tidyverse)
library(broom)
library(knitr)
library(lazyeval)
```

## Utility functions

Format $p$-values with `**` (`*`) if the corresponding test is significant at the 1% (5%) level.

```{r}
pv_to_stars <- function(pv) {
  cvt <- c(" ", "*")
  paste0(cvt[(pv <= 0.05) + 1], cvt[(pv <= 0.01) + 1])
}
```

```{r}
# Taken from <http://www.stat.umn.edu/geyer/old/5601/examp/kolmogorov.html#one-ci>
pksone <- function(x) {
  k <- seq(1:20)
  1 + 2 * sum( (-1)^k * exp(-2 * k^2 * x^2))
}

qksone <- function(alpha) {
  if (alpha > 0.5)
    stop("don't do less than 50% confidence")
  foo <- function(x) pksone(x) - 1 + alpha
  uniroot(foo, c(0.5, 10), tol = 1e-8)$root
}
```


# Data

The data from the experimental sessions described in the paper are stored in three files:

- `./data/treatments.csv`: treatment design variables. 
- `./data/subjects.csv`: lotteries results. 
- `./data/prices.csv`: prices.


## Treatment design variables

The variable `phi` is computed on the fly.

```{r}
treat_db <- read_csv('./data/treatments.csv', col_types = "ilii") %>%
  mutate(phi = if_else(selective, 1, k/n))

glimpse(treat_db)
```

Variables:

- `treat_id`: the treatment id.
- `selective`: `TRUE` if the treatment's platform is selective. 
- `n`: number of firms in each treatment's market.
- `k`: number of firms in the index, $k \leq n$.
- `phi`: the ex-ante probability of being included in the index for the fims that actually ended up being indexed. 

## Lotteries results

The lotteries data are not used in this paper.

```{r}
subjects_db <- read_csv('./data/subjects.csv', col_types = "idddd")
glimpse(subjects_db)
```

Variables:

- `subject_id`: the subject id.
- `p1, p2, p3, p4`: subject's lottery choices in each of the four panels; a double between 0.0 and 1.0. 


## Prices 

- 8 treatments. 
- 18 subjects participated in each treatment.
- Each treatment run for 50 periods.
- Each subject was randomly assigned to a market every period. Markets were composed of three or six subjects, depending on the treatment.
- Before posting a price each subject knew the probability that its price could be indexed.
- Each market participant posted a price. The firm with the lowest indexed price would sell to the shoppers. The other firms would only sell to their captive consumers.

```{r}
prices_db <- read_csv('./data/prices.csv', col_types = "iiiild")
glimpse(prices_db)
```

Variables:

- `treat_id`: treatment id.
- `market_id`: market id.
- `period`: time period.
- `subject_id`: subject id.
- `indexed`: `TRUE` if the price is included in the index.
- `price`: the price; a double between 0.0 and 1.0.

## Sample

We first build the `smpl_db` database. The first 20 periods are dropped from the sample and never used in the statistical analyses. 

We compute a new categorical variable, `part`, that divide the remaining sample in three parts: the first 10 periods, the central 10 periods and the final 10 periods. This variable will be used later when testing for trends. 

From data in the prices database, we also compute two new price variables:

- `pindexable`: all prices that could be indexed, i.e., all prices in unselective coverage treatments and those from indexed vendors in selective coverage treatments. Average market prices are based on this variable. The plots of empirical distribution functions also use this variable.
- `pindexed`: only the prices of indexed vendors in every treatment. The minimum of these prices in each market is the price paid by shoppers. 

```{r}
smpl_db <- left_join(prices_db, treat_db, by = 'treat_id') %>% 
  filter(period > 20) %>%
  mutate(pindexable = if_else(!selective | indexed, price, NA_real_),
         pindexed = if_else(indexed, price, NA_real_),
         part = as.integer(floor((period  - 1) / 10) - 1)) %>%
  select(-one_of(c("selective", "n", "k", "phi")))
```

We use the database `plots_db` for plotting distribution functions. This database is a simplified version of `smpl_db` database. We only keep the `treat_id`, `part` and `pindexable` variables, the latter simpl renamed `p`, and we drop all observations that correspond to firms not appearing in the index with probability 1:

```{r}
plots_db <- filter(smpl_db, !is.na(pindexable)) %>% 
  select(treat_id, period, p = pindexable)
```

Most of the tests in this paper are about expected prices. The `markets_db` database contains two new variables built from price averages:

- `pavg`: the expected market price, excluding the prices set by firms with no likelihood of being indexed.

- `pmin`: the minimum of the indexed prices in each market.

```{r}
markets_db <- smpl_db %>% group_by(market_id) %>%
  summarise(treat = first(treat_id),
            period = first(period),
            part = first(part),
            pavg = mean(pindexable, na.rm = TRUE),
            pmin = min(pindexed, na.rm = TRUE)) 
```



# Equilibrium price distributions

The equilibrium price distribution is given by
\begin{equation*}
F(p; n, k, \phi, \lambda) = 
\begin{cases}
0 & 0 \leq p < l \\
1 - \left[
  \dfrac{1}{n \phi}
  \dfrac{\lambda}{1 - \lambda}
  \dfrac{1 - p}{p}
\right]^{1/(k-1)}
& l \leq p \leq 1 
\end{cases}
\end{equation*}
where 
\begin{equation*}
l = \frac{\lambda}{\lambda + (1 - \lambda) n \phi}
\end{equation*}

The following function computes `l`, the lower limit of the support of the equlibrium distribution:
```{r}
Fsearch_low <- function(n, k, phi, lambda = 1 / 2) {
  lambda / (lambda + (1 - lambda) * n * phi)
}
```


We use a function factory to build the cdf for a given combination of parameters:

```{r}
Fsearch <- function(n, k, phi, lambda = 1 / 2) {
  # These are the same for all invokations
  const <- (lambda / (1 - lambda)) / (n * phi)
  low <- Fsearch_low(n, k, phi, lambda)
  pow <- 1 / (k - 1)
  
  # Return a function that computes the cdf
  function(p) {
    # Handle vector arguments. Default case: p <= l
    prob <- rep_along(p, 0)

    # Second case: p >= 1
    idx <- p >= 1.0
    if (any(idx)) {
      prob[idx] <- 1.0
    }

    # Third case: l < p < 1
    idx <- p > low & p < 1.0
    if(any(idx)) {
      pi <- p[idx]
      prob[idx] <- 1 - (const * (1 - pi) / pi) ^ pow
    }
   
    prob
  }
}
```

As prices are non-negative random variables, we will compute their expectation as:
\begin{equation*}
  E(p) = \int_{0}^{\infty} 1 - F(p)\; dp
\end{equation*}
We will use the following functional operator to obtain a function that computes the complement of a cdf:

```{r}
compl_cdf <- function(cdf) {
  function(x) {
    1 - cdf(x)
  }
}
```

Another useful result for non-negative random variables:
\begin{equation*}
  E(p^2) = 2 \int_{0}^{\infty} p \big(1 - F(p)\big)\; dp
\end{equation*}
We will compute the above formula with the help of the following functional operator:

```{r}
func_arg <- function(func) {
  function(x) {
    func(x) * x
  }
}
```

Finally, the cdf of the minimum of $n$ random variables, all of them with cdf $F(p)$, is given by:
\begin{equation*}
  G(p) = 1 - \big[ 1 - F(p) \big]^n
\end{equation*}
The next functional operator will be useful:

```{r}
func_pow <- function(func, pow) {
  function(x) {
    func(x)^pow
  }
}
```

Using the above results, the following function numerically evaluates some moments of the expected and minimum market price distributions. It computes the mean and standard deviation of the equilibrium distribution of average market prices, `pavg`, and minimum market prices, `pmin`:

```{r}
eq_moments <- function(n, k, phi, treat_id, selective) {
  mean_sd <- function(ccdf, num = 1) {
    # E(X)
    EX <- integrate(ccdf, lower = 0, upper = 1)$value
    # E(X^2)
    EX2 <- 2 * integrate(func_arg(ccdf), lower = 0, upper = 1)$value
    # Var(X)
    VX <-  EX2 - EX^2
    list(mu = EX, sd = sqrt(VX) / sqrt(num))
  }
  
  # Complement of the cdf
  ccdf <- compl_cdf(Fsearch(n = n, k = k, phi = phi))
  
  # In selective treatments only k prices are averaged.
  pavg_mom <- mean_sd(ccdf, if_else(selective, k, n))
  
  pmin_mom <- mean_sd(func_pow(ccdf, k))
  tibble(treat = treat_id, 
         pavg_mean = pavg_mom$mu, pavg_sd = pavg_mom$sd,
         pmin_mean = pmin_mom$mu, pmin_sd = pmin_mom$sd)  
}
```

Table with moments of the equilibrium price distributions for the 8 treatments. These results are reported in Table 1 of the paper.

```{r}
mom_df <- treat_db %>% pmap_df(eq_moments)
kable(mom_df, digits = 3, 
      col.names = c("Treatment", 
                    "pavg: mean", "pavg: sd",
                    "pmin: mean", "pmin: sd"))
```




# Results

## Trends

In this paper, we focus on average prices and not on prices set by each firm across time. We use anumber of strategies to detect the presence of trends in data.  First, we use simple plots of expected prices against time. 

```{r}
trend_plots <- function(var) {
  ggplot(data = markets_db, mapping = aes_(x = ~period, y = var)) +
    geom_point(size=0.4) +
    coord_cartesian(ylim = c(0, 1)) +
    facet_wrap(ncol=2, ~ treat)  +
    geom_smooth(method = "lm", size = 0.6)
}
```

Second, we split the sample in three parts and use Kruskal-Wallis tests to check the hypothesis that the mean of expected prices is the same across all periods.  We also carry out another version of this test, where the central periods are dropped, and the null hypothesis is the equality of means in the first part and the last part. 

```{r}
kw_tests <- function(data, frml, by_var) {
  data %>% group_by_(by_var) %>% 
    do(tidy(kruskal.test(frml, data = .))) %>%
    mutate(pv = pv_to_stars(p.value)) %>%
    select(-one_of(c("method", "parameter", "p.value")))
}
```


Finally, we test if average prices are associated with a trend variable. We use the Kendall correlation coefficient in order to allow for possible nonlinear associations.  


```{r}
corr_tests <- function(data, frml, by_var, method = "kendall") {
  inner <- function(data, frml, method) {
    f_env(frml) <- environment()
    cor.test(frml, method = method, data = data)
  }
  
  data %>% group_by_(by_var) %>% 
    do(tidy(inner(., frml, method))) %>%
    mutate(pv = pv_to_stars(p.value)) %>%
    select(-one_of(c("method", "statistic", "alternative", "p.value"))) 
}
```

The following function collect the above tests and summarize the results:

```{r}
trend_tests <- function(var, group, filter_frml) {
  kw_frml <- f_new(uq(group), uq(var))
  # Kruskal-Wallis using all periods
  kw1 <- kw_tests(markets_db, kw_frml,  ~treat)
  
  # Kruskal-Wallis dropping the central periods:
  kw2 <- kw_tests(filter_(markets_db, filter_frml), kw_frml, ~treat)

  # Kendall correlation tests
  kend_frml <- f_interp(~uq(var) + period)
  kend <- corr_tests(markets_db, kend_frml, ~treat)
  
  # Bind the three tables; rename the columns.
  left_join(kw1, kw2, by = "treat") %>%
    rename(kw_all = statistic.x, kw_drop = statistic.y) %>%
    left_join(kend, by = "treat") %>%
    rename(kendall = estimate)
}
```



Plots for the average market prices:

```{r fig.height=8.75}
trend_plots(~pavg)
```

Plots for the minimum market prices:

```{r fig.height=8.75}
trend_plots(~pmin)
```



Tests for the average market prices:

```{r}
trend_tests(~pavg,  ~part, ~ part != 2) %>%
  kable(digits = 3, 
        col.names = c("Treatment", 
                      "KW (All)", "", "KW (Drop)", "", "Kendall", ""))
```

Tests for the minimum market prices:

```{r}
trend_tests(~pmin,  ~part, ~ part != 2) %>%
  kable(digits = 3, 
        col.names = c("Treatment", 
                      "KW (All)", "", "KW (Drop)", "", "Kendall", ""))
```

Conclusions:

- There is some evidence of the presence of trends in some of the treatments. 
- Generally speaking, the trends are not very steep and the association of prices with the trend variable is not strong. 


## Descriptive statistics

Utility function that computes tests on the mean of the price distributions.
```{r}
mean_tests <- function(data, var, by_var, test_func = t.test, ...) {
  data %>% 
    mutate_(x = var) %>% 
    group_by_(by_var) %>%  
    do(tidy(test_func(.$x, ...))) %>%
    mutate(pv = pv_to_stars(p.value)) %>%
    select_(by_var, "statistic", "pv")
}
```


Descriptive statistics reported on Table 1:

```{r}
summ_mean_tests <- function(data, var, var_test, by_var) {
  dstats <- data %>% group_by_(by_var) %>%
    summarise_('Mean' = f_interp(~mean(uq(var))), 
               'SD' = f_interp(~sd(uq(var))))

  test1 <- data %>% 
    mean_tests(var = var_test, by_var = by_var) %>%
    rename(t = statistic, pv_t = pv)

  test2 <- data %>% 
    mean_tests(var = var_test, by_var = by_var, 
               test_func = wilcox.test, exact = FALSE) %>%
    rename(W = statistic, pv_W = pv)
  
  left_join(dstats, test1, by = "treat") %>%
    left_join(test2, by = "treat")
}
```

```{r}
tests_db <- left_join(markets_db, mom_df, by = "treat") 
```

```{r}
summ_mean_tests(data = tests_db,
                var = ~pavg,
                var_test = ~pavg - pavg_mean,
                by_var = ~treat) %>%
  kable(digits = c(1, 3, 3, 1, 1, 1, 1), 
        col.names = c("Treatment", "Mean", "SD", "t", "", "W", ""),
        align = "lrrrlrl")
```


Wilcoxon test on means of average prices:

```{r}
summ_mean_tests(data = tests_db,
                var = ~pmin,
                var_test = ~pmin - pmin_mean,
                by_var = ~treat) %>%
  kable(digits = c(1, 3, 3, 1, 1, 1, 1), 
        col.names = c("Treatment", "Mean", "SD", "t", "", "W", ""),
        align = "lrrrlrl")
```



Descriptive statistics for observations from the 10 last periods:

```{r}
summ_mean_tests(data = filter(tests_db, part == 3),
                var = ~pavg,
                var_test = ~pavg - pavg_mean,
                by_var = ~treat) %>%
  kable(digits = c(1, 3, 3, 1, 1, 1, 1), 
        col.names = c("Treatment", "Mean", "SD", "t", "", "W", ""),
        align = "lrrrlrl")
```


Wilcoxon test on means of average prices:

```{r}
summ_mean_tests(data = filter(tests_db, part == 3),
                var = ~pmin,
                var_test = ~pmin - pmin_mean,
                by_var = ~treat) %>%
  kable(digits = c(1, 3, 3, 1, 1, 1, 1), 
        col.names = c("Treatment", "Mean", "SD", "t", "", "W", ""),
        align = "lrrrlrl")
```



## Tests

```{r}
treat_test <- function(var, group_var, g1, g2, data, ...,
                       test_func = t.test) {
  x <- data[[var]]
  g <- data[[group_var]]
  test_func(x[g == g1], x[g == g2], ...)
} 

fmt_tests <- function(g1, g2, H1, statistic, p.value, prefix = "eps_") {
  cvt <- c("less" = " < ", "greater" = " > ", "two.sided" = " != ")
  H1str <- paste(prefix, g1, cvt[H1], prefix, g2, sep = "")
  tibble(H1 = H1str, stat = statistic, pv = pv_to_stars(p.value))
}

treat_map <- function(var, g1, g2, H1, ...) {
  test <- treat_test(var, "treat", g1, g2, alternative = H1, ...)
  c(g1 = g1, g2 = g2, H1 = H1, test[c("statistic", "p.value")])
}

pavg_map <- function(g1, g2, H1, ...) {
  treat_map("pavg", g1, g2, H1, ...)
}

pmin_map <- function(g1, g2, H1, ...) {
  treat_map("pmin", g1, g2, H1, ...)
}

pavg_hyp <- list(g1 = c(1, 5, 7, 7, 2, 2, 6, 8, 8, 3, 8, 6, 8, 3),
                 g2 = c(4, 4, 4, 5, 1, 7, 4, 4, 6, 1, 3, 5, 7, 2),
                 H1 = c(rep("less", 5), "two.sided", rep("less", 8)))

pmin_hyp <- list(g1 = c(4, 4, 4, 5, 1, 2, 6, 8, 8, 3, 8, 6, 8, 3),
                 g2 = c(1, 5, 7, 7, 2, 7, 4, 4, 6, 1, 3, 5, 7, 2),
                 H1 = c(rep("less", 5), "two.sided", rep("less", 8)))

```

```{r}
left_join(pmap_df(pavg_hyp, pavg_map, data = markets_db, 
                  var.equal = TRUE) %>% pmap_df(fmt_tests), 
          pmap_df(pavg_hyp, pavg_map, data = markets_db, exact = FALSE, 
                  test_func = wilcox.test)  %>% pmap_df(fmt_tests),
          by = "H1") %>%
  kable(digits = 2, col.names = c("H1", "t", "", "W", ""))
```

```{r}
left_join(pmap_df(pmin_hyp, pmin_map, data = markets_db, 
                  var.equal = TRUE) %>% pmap_df(fmt_tests, prefix = "mu_"), 
          pmap_df(pmin_hyp, pmin_map, data = markets_db, exact = FALSE, 
                  test_func = wilcox.test)  %>% 
            pmap_df(fmt_tests, prefix = "mu_"),
          by = "H1") %>%
  kable(digits = 2, col.names = c("H1", "t", "", "W", ""))
```


```{r}
markets3 <- filter(markets_db, part == 3)

left_join(pmap_df(pavg_hyp, pavg_map, data = markets3, 
                  var.equal = TRUE) %>% pmap_df(fmt_tests), 
          pmap_df(pavg_hyp, pavg_map, data = markets3, exact = FALSE, 
                  test_func = wilcox.test)  %>% pmap_df(fmt_tests),
          by = "H1") %>%
  kable(digits = 2, col.names = c("H1", "t", "", "W", ""))
```

```{r}
left_join(pmap_df(pmin_hyp, pmin_map, data = markets3, 
                  var.equal = TRUE) %>% pmap_df(fmt_tests, prefix = "mu_"), 
          pmap_df(pmin_hyp, pmin_map, data = markets3, exact = FALSE, 
                  test_func = wilcox.test)  %>% 
            pmap_df(fmt_tests, prefix = "mu_"),
          by = "H1") %>%
  kable(digits = 2, col.names = c("H1", "t", "", "W", ""))
```

## Distribution plots


```{r}
emp_dist <- function(var, alpha) {
  cv <- qksone(alpha) / sqrt(length(var)) 
  dist <- ecdf(var)
  x <- knots(dist)
  y <- dist(x)
  lower <- pmax(y - cv, 0)
  upper <- pmin(y + cv, 1)
  list(x = x, y = y,ylo = lower,yhi = upper)
}

ecdf_df <- plots_db %>% 
  group_by(treat_id) %>% 
  do(as_data_frame(emp_dist(.$p, alpha = 0.01))) 
```

```{r}
eq_dist <- function(treat_id, n, k, phi, lambda = 1 / 2) {
  low <- Fsearch_low(n, k, phi, lambda)
  x <- seq(low, 1, length.out = 128)
  y <- Fsearch(n, k, phi, lambda)(x)
  tibble(treat_id = treat_id, x = x, y = y)
} 

eq_df <- pmap_df(select(treat_db, -one_of("selective")), eq_dist)
```


```{r fig.height=8.5}
treat_plots <- function(data) {
  ggplot(data = data, aes(x = x, y = y)) +
    geom_line(data = eq_df, aes(x = x, y = y, 
                                color=I("green4")), size = I(0.6)) +
    geom_ribbon(aes(ymin = ylo, ymax = yhi, alpha = 1/20, 
                    fill = I("steelblue2"))) +
    geom_step(aes(color=I("blue4")), size = I(0.6)) +
    facet_wrap(ncol = 3, ~ treat_id) +
    theme(legend.position="none") +
    scale_x_continuous(name = "p", breaks = (1:3)/4, 
                       labels = c("0.25", "0.50", "0.75")) + 
    scale_y_continuous(name = "cdf", breaks = (1:3)/4, 
                       labels = c("0.25", "0.50", "0.75")) + 
    coord_fixed(ratio = 1, xlim = c(0, 1), ylim = c(0, 1), expand = FALSE) + 
    xlab("p") + ylab("cdf")
}

treat_plots(ecdf_df)
```

```{r}
plot_pair <- function(data, t1, t2) {
  filter_(data, ~treat_id == t1 | treat_id == t2) %>%
    mutate(treat = as.factor(treat_id)) %>%
    ggplot(aes(x = x, y = y)) +
    geom_line(mapping = aes(group = treat, color = treat), 
              size = I(0.6)) +
    scale_color_discrete(name = "Treatment") + 
    scale_x_continuous(name = "p", breaks = (1:3)/4, 
                       labels = c("0.25", "0.50", "0.75")) + 
    scale_y_continuous(name = "cdf", breaks = (1:3)/4, 
                       labels = c("0.25", "0.50", "0.75")) + 
    coord_fixed(ratio = 1, xlim = c(0, 1), ylim = c(0, 1), expand = FALSE)
}
```


```{r fig.height=2.6}
plot_pair(ecdf_df, 1, 4)
```


```{r fig.height=8}
p1 <- plot_pair(ecdf_df, 2, 3)
p2 <- plot_pair(ecdf_df, 5, 6)
p3 <- plot_pair(ecdf_df, 7, 8)
grid.arrange(p1, p2, p3, ncol = 1)
```

```{r fig.height=8.5}
ecdf_df3 <- filter(plots_db, period > 40) %>% 
  group_by(treat_id) %>% 
  do(as_data_frame(emp_dist(.$p, alpha = 0.01))) 

treat_plots(ecdf_df3)
```

```{r fig.height=2.6}
plot_pair(ecdf_df3, 1, 4)
```

```{r fig.height=8}
p1 <- plot_pair(ecdf_df3, 2, 3)
p2 <- plot_pair(ecdf_df3, 5, 6)
p3 <- plot_pair(ecdf_df3, 7, 8)
grid.arrange(p1, p2, p3, ncol = 1)
```
